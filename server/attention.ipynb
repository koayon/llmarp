{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from fancy_einsum import einsum\n",
    "from fastapi import FastAPI\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from dataclasses import dataclass\n",
    "import tiktoken\n",
    "import seaborn as sns\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Looking at GPT-2 Small first\n",
    "model = HookedTransformer.from_pretrained(\"gpt2\", device=device)\n",
    "model_cfg = model.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Prediction:\n",
    "    next_token: str\n",
    "    top5_tokens: List[str]\n",
    "    confidence_in_guess: float\n",
    "    confidence_in_top_5: float\n",
    "    attention: List[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a.sort(-1, descending=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: \n",
    "You give me a sequence of tokens, for each subsequence I give you back: \n",
    "- The best prediction for next token\n",
    "- How confident I am\n",
    "- My top 5 guesses\n",
    "- The attention pattern I used to get this guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(sequence: str, model: HookedTransformer = model, topk: int = 5) -> Tuple[str, float, List[str]]:\n",
    "    \"Return the next token, confidence in the guess and top 5 guesses\"\n",
    "    logits = model(sequence) # batch (1), sequence length, vocab size\n",
    "    \n",
    "    logits_most_to_least_likely, tokens_most_to_least_likely = logits.sort(-1, descending =True) # batch (1), sequence length, vocab size\n",
    "    print(logits_most_to_least_likely.shape)\n",
    "    \n",
    "    probs_most_to_least_likely = torch.softmax(logits_most_to_least_likely, dim=-1)[0]\n",
    "    confidence_in_top_guess = probs_most_to_least_likely[-1, 0].item()\n",
    "    \n",
    "    top_predictions = tokens_most_to_least_likely[0, :, :topk] # sequence length, topk\n",
    "    final_top_predictions = top_predictions[-1, :]\n",
    "\n",
    "    print(top_predictions.shape)\n",
    "    print(top_predictions)\n",
    "    topk_predictions = model.to_str_tokens(final_top_predictions) \n",
    "    return topk_predictions[0], confidence_in_top_guess, topk_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predictions(sequence: str, model: HookedTransformer = model, topk: int = 5) -> Tuple[List[str], List[float], List[List[str]]]:\n",
    "    \"Return next guess for each substring, confidence in the guess and top 5 guesses\"\n",
    "    logits = model(sequence) # batch (1), sequence length, vocab size\n",
    "    \n",
    "    logits_most_to_least_likely, tokens_most_to_least_likely = logits.sort(-1, descending =True) # batch (1), sequence length, vocab size\n",
    "    print(logits_most_to_least_likely.shape)\n",
    "    \n",
    "    probs_most_to_least_likely = torch.softmax(logits_most_to_least_likely, dim=-1)[0]\n",
    "    confidence_in_top_guesses = probs_most_to_least_likely[:, 0].numpy().tolist()\n",
    "    confidence_in_top_guesses = [round(confidence, 3) for confidence in confidence_in_top_guesses]\n",
    "    \n",
    "    top_predictions = tokens_most_to_least_likely[0, :, :topk] # sequence length, topk\n",
    "    \n",
    "    topk_predictions = []\n",
    "    for i, token in enumerate(top_predictions): \n",
    "        topk_predictions.append(model.to_str_tokens(top_predictions[i]))\n",
    "        \n",
    "    best_guesses = [guess[0] for guess in topk_predictions]\n",
    "\n",
    "    print(top_predictions.shape)\n",
    "    print(top_predictions)\n",
    "\n",
    "    # topk_predictions = model.to_str_tokens(final_top_predictions)  \n",
    "    return best_guesses, confidence_in_top_guesses, topk_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to_str_tokens(top_predictions[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 50257])\n",
      "torch.Size([9, 5])\n",
      "tensor([[ 198,  464,    1,   32,   40],\n",
      "        [  13,    8, 5985,  198,  362],\n",
      "        [ 830, 4059, 2167,   23,   24],\n",
      "        [  11,   12,   13,    8,  198],\n",
      "        [  18,   19,   20,   17,   16],\n",
      "        [  11,   12,  198,    8,   13],\n",
      "        [  19,   20,   18,   21,   16],\n",
      "        [  11,  198,   12,    8,   13],\n",
      "        [  20,   21,   19,   16,   22]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['\\n', '.', '000', ',', '3', ',', '4', ',', '5'],\n",
       " [0.062, 0.272, 0.122, 0.282, 0.779, 0.514, 0.899, 0.693, 0.924],\n",
       " [['\\n', 'The', '\"', 'A', 'I'],\n",
       "  ['.', ')', ' Clean', '\\n', ' 2'],\n",
       "  ['000', '500', '200', '8', '9'],\n",
       "  [',', '-', '.', ')', '\\n'],\n",
       "  ['3', '4', '5', '2', '1'],\n",
       "  [',', '-', '\\n', ')', '.'],\n",
       "  ['4', '5', '3', '6', '1'],\n",
       "  [',', '\\n', '-', ')', '.'],\n",
       "  ['5', '6', '4', '1', '7']])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_predictions(\"1,2,3,4,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_pattern(sequence: str, model: HookedTransformer = model) -> list:\n",
    "    logits, cache = model.run_with_cache(sequence, remove_batch_dim=True)\n",
    "    attention_patterns = [cache[\"pattern\", layer, \"attn\"] for layer in range(12)]\n",
    "    attention_patterns = torch.stack(attention_patterns, dim=0)  # layer, head, seq, seq\n",
    "    reduced_attention = einops.reduce(\n",
    "        attention_patterns, \"layer head i j -> i j\", \"mean\"\n",
    "    )\n",
    "    # final_token_attention = reduced_attention[-1]\n",
    "    # final_token_attention = final_token_attention[1:]\n",
    "    # print(reduced_attention, reduced_attention.shape)\n",
    "    reduced_attention[0,:] = 0\n",
    "    reduced_attention[:,0] = 0\n",
    "    # reduced_attention = reduced_attention[1:, 1:]\n",
    "    # rescale to sum to 1\n",
    "    attention = reduced_attention / reduced_attention.sum(\n",
    "        -1, keepdims=True\n",
    "    )\n",
    "    attention[0, :] = 0\n",
    "    print(attention, attention.shape)\n",
    "    fig = sns.heatmap(attention)\n",
    "    fig.show()\n",
    "    return attention.numpy().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-fe3da0f0-2da9\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-fe3da0f0-2da9\",\n",
       "      Hello,\n",
       "      {\"name\": \"Neel\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x191d74250>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing that the library works\n",
    "cv.examples.hello(\"Neel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 Head Attention Patterns:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-40f18efb-02e8\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-40f18efb-02e8\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<|endoftext|>\", \"1\", \",\", \"2\", \",\", \"3\", \",\", \"4\", \",\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9872710108757019, 0.012729010544717312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9486905932426453, 0.033025335520505905, 0.01828400418162346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8245161771774292, 0.03222202509641647, 0.12543076276779175, 0.017830995842814445, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8911048769950867, 0.04118942841887474, 0.020299185067415237, 0.02885354682803154, 0.01855297200381756, 0.0, 0.0, 0.0, 0.0], [0.6427176594734192, 0.04633833467960358, 0.12614576518535614, 0.033250052481889725, 0.11887983977794647, 0.03266838937997818, 0.0, 0.0, 0.0], [0.8541288375854492, 0.04023287817835808, 0.01739802397787571, 0.028164613991975784, 0.016114652156829834, 0.02751033753156662, 0.01645052433013916, 0.0, 0.0], [0.584606945514679, 0.03512085974216461, 0.1072007492184639, 0.023031283169984818, 0.10076524317264557, 0.021160639822483063, 0.1087181493639946, 0.01939617656171322, 0.0], [0.811616837978363, 0.037210557609796524, 0.015221266075968742, 0.02657431550323963, 0.014151379466056824, 0.026086417958140373, 0.014508606866002083, 0.03923746570944786, 0.015393090434372425]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0037950703408569098, 0.9962049126625061, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010201514698565006, 0.001198739162646234, 0.9885997772216797, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010987994028255343, 0.013801333494484425, 0.0009306083666160703, 0.9841692447662354, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0038578417152166367, 0.00039497343823313713, 0.5380436778068542, 0.00013502224464900792, 0.45756855607032776, 0.0, 0.0, 0.0, 0.0], [0.0010324702598154545, 0.007945812307298183, 0.0008129092748276889, 0.009618951007723808, 0.0004449202388059348, 0.9801449775695801, 0.0, 0.0, 0.0], [0.0024511830415576696, 0.00020106158626731485, 0.35350480675697327, 7.123328396119177e-05, 0.32864704728126526, 4.612721750163473e-05, 0.3150785565376282, 0.0, 0.0], [0.0004345885245129466, 0.001689664088189602, 0.0007545799599029124, 0.003990323282778263, 0.00040882208850234747, 0.0022903159260749817, 0.0002915441582445055, 0.9901401400566101, 0.0], [0.0018403088906779885, 0.00012988439993932843, 0.25111067295074463, 4.722287485492416e-05, 0.24985060095787048, 3.3220530895050615e-05, 0.25065910816192627, 5.562591104535386e-05, 0.2462732493877411]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445667862892151, 0.05543321371078491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6116600632667542, 0.031502898782491684, 0.35683709383010864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6236178278923035, 0.18170224130153656, 0.056927390396595, 0.13775253295898438, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3591573238372803, 0.02613246627151966, 0.31962573528289795, 0.019768955186009407, 0.27531546354293823, 0.0, 0.0, 0.0, 0.0], [0.41865044832229614, 0.17908836901187897, 0.06367083638906479, 0.16076180338859558, 0.051741424947977066, 0.12608712911605835, 0.0, 0.0, 0.0], [0.25356024503707886, 0.019713453948497772, 0.2496509850025177, 0.015583313070237637, 0.22350527346134186, 0.009396075271070004, 0.22859060764312744, 0.0, 0.0], [0.36034059524536133, 0.14664827287197113, 0.050192445516586304, 0.1391158550977707, 0.041250113397836685, 0.12974907457828522, 0.0389116145670414, 0.09379208832979202, 0.0], [0.19772745668888092, 0.01520226988941431, 0.1983647346496582, 0.012506198137998581, 0.18214018642902374, 0.007567426655441523, 0.18792015314102173, 0.007765492890030146, 0.19080618023872375]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2637639045715332, 0.7362360954284668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3064247965812683, 0.12175906449556351, 0.5718162059783936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018979081884026527, 0.06915450096130371, 0.046832118183374405, 0.8650343418121338, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12852570414543152, 0.04927247762680054, 0.18424321711063385, 0.05593691021203995, 0.5820216536521912, 0.0, 0.0, 0.0, 0.0], [0.009069306775927544, 0.007572992704808712, 0.004019292537122965, 0.03971661254763603, 0.017908170819282532, 0.921713650226593, 0.0, 0.0, 0.0], [0.06334195286035538, 0.01431281678378582, 0.045684777200222015, 0.013471009209752083, 0.15898582339286804, 0.08342460542917252, 0.6207790374755859, 0.0, 0.0], [0.002148863859474659, 0.0017421124503016472, 0.000641179911326617, 0.004610575269907713, 0.003202628344297409, 0.05821702629327774, 0.016075124964118004, 0.9133625030517578, 0.0], [0.0353931188583374, 0.004380693193525076, 0.012691237032413483, 0.0034345306921750307, 0.041581686586141586, 0.02091771364212036, 0.1694842129945755, 0.06090337038040161, 0.6512133479118347]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9062865972518921, 0.09371335059404373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6399704217910767, 0.14919057488441467, 0.21083898842334747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4255900979042053, 0.19517166912555695, 0.09272067248821259, 0.28651759028434753, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3376534879207611, 0.1091836541891098, 0.16149701178073883, 0.12316788733005524, 0.268498033285141, 0.0, 0.0, 0.0, 0.0], [0.33514320850372314, 0.08919165283441544, 0.052894677966833115, 0.12154022604227066, 0.08375006914138794, 0.3174801766872406, 0.0, 0.0, 0.0], [0.19533133506774902, 0.05672695115208626, 0.08789842575788498, 0.06287914514541626, 0.15605103969573975, 0.1338251680135727, 0.3072879910469055, 0.0, 0.0], [0.1609826385974884, 0.048460498452186584, 0.0353156179189682, 0.06554751098155975, 0.057011205703020096, 0.13156446814537048, 0.09999721497297287, 0.4011208117008209, 0.0], [0.12089870125055313, 0.029573524370789528, 0.04568114131689072, 0.031455833464860916, 0.07893332839012146, 0.06597130000591278, 0.15835104882717133, 0.15750424563884735, 0.31163081526756287]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22788068652153015, 0.7721192836761475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41381630301475525, 0.1627330183982849, 0.4234507381916046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10878140479326248, 0.011368799954652786, 0.000492140359710902, 0.8793576955795288, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20835794508457184, 0.1570766419172287, 0.32257047295570374, 0.05437484756112099, 0.25762009620666504, 0.0, 0.0, 0.0, 0.0], [0.0654372051358223, 0.005262576974928379, 0.00031509928521700203, 0.004587383940815926, 0.0001606430159881711, 0.9242371320724487, 0.0, 0.0, 0.0], [0.11721242219209671, 0.14771710336208344, 0.25516897439956665, 0.051256660372018814, 0.2008211463689804, 0.04870857670903206, 0.1791151463985443, 0.0, 0.0], [0.041501231491565704, 0.002503044903278351, 0.00015799391258042306, 0.004365710541605949, 6.489370571216568e-05, 0.002771570812910795, 4.033721052110195e-05, 0.9485952258110046, 0.0], [0.07840470224618912, 0.13738802075386047, 0.21186095476150513, 0.04722509905695915, 0.16499197483062744, 0.042735014110803604, 0.14607493579387665, 0.034952688962221146, 0.1363665908575058]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9654070138931274, 0.03459293395280838, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8043868541717529, 0.17691916227340698, 0.018693948164582253, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6933765411376953, 0.13394255936145782, 0.06889402121305466, 0.10378686338663101, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6107672452926636, 0.1963513195514679, 0.021300993859767914, 0.15370263159275055, 0.017877837643027306, 0.0, 0.0, 0.0, 0.0], [0.48272356390953064, 0.15062181651592255, 0.053696826100349426, 0.12172188609838486, 0.047910433262586594, 0.1433255821466446, 0.0, 0.0, 0.0], [0.49311569333076477, 0.16880586743354797, 0.017220573499798775, 0.1441967636346817, 0.014869255013763905, 0.14707185328006744, 0.014720071107149124, 0.0, 0.0], [0.4020163118839264, 0.09627954661846161, 0.06047661602497101, 0.09454517811536789, 0.05602767691016197, 0.10800740867853165, 0.05564647540450096, 0.12700071930885315, 0.0], [0.4188152551651001, 0.14039836823940277, 0.013654811307787895, 0.12575435638427734, 0.011967909522354603, 0.12937496602535248, 0.011916517280042171, 0.13567925989627838, 0.012438612058758736]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9809219241142273, 0.019078116863965988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42653557658195496, 0.3716674745082855, 0.20179688930511475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3667612671852112, 0.1890420913696289, 0.2558157742023468, 0.18838080763816833, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17802168428897858, 0.15481016039848328, 0.12031427770853043, 0.296850323677063, 0.2500036060810089, 0.0, 0.0, 0.0, 0.0], [0.19522568583488464, 0.061927467584609985, 0.12194724380970001, 0.14438940584659576, 0.28080102801322937, 0.195709228515625, 0.0, 0.0, 0.0], [0.08976307511329651, 0.0621270090341568, 0.04823676496744156, 0.12005168199539185, 0.11144523322582245, 0.30616286396980286, 0.2622133493423462, 0.0, 0.0], [0.10369838774204254, 0.041996948421001434, 0.045877065509557724, 0.0816715806722641, 0.11270327866077423, 0.12344736605882645, 0.26353520154953003, 0.22707019746303558, 0.0], [0.05439474806189537, 0.0271088108420372, 0.020922191441059113, 0.05092298239469528, 0.048364099115133286, 0.1287737786769867, 0.11670897156000137, 0.2751784920692444, 0.2776259183883667]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8457146286964417, 0.15428532660007477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29242709279060364, 0.0856155976653099, 0.6219573020935059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31655773520469666, 0.21566450595855713, 0.3258651793003082, 0.1419125497341156, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11287542432546616, 0.048009369522333145, 0.3715122938156128, 0.04515548422932625, 0.42244744300842285, 0.0, 0.0, 0.0, 0.0], [0.1688717007637024, 0.14418242871761322, 0.21539871394634247, 0.11438015848398209, 0.2393159568309784, 0.11785101145505905, 0.0, 0.0, 0.0], [0.06521860510110855, 0.03047848679125309, 0.24120432138442993, 0.02995249815285206, 0.282490998506546, 0.02285310998558998, 0.32780197262763977, 0.0, 0.0], [0.1273687481880188, 0.12109477818012238, 0.13621816039085388, 0.09485456347465515, 0.15146100521087646, 0.11015450954437256, 0.17015895247459412, 0.08868931978940964, 0.0], [0.04552833363413811, 0.021464450284838676, 0.1707569807767868, 0.021711938083171844, 0.20390021800994873, 0.01698416657745838, 0.2380291372537613, 0.01652544178068638, 0.26509925723075867]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8588211536407471, 0.14117877185344696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7200052738189697, 0.13159354031085968, 0.1484011709690094, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5687281489372253, 0.15959249436855316, 0.1518598198890686, 0.11981955170631409, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5408440232276917, 0.11866312474012375, 0.13236647844314575, 0.0900193601846695, 0.11810693889856339, 0.0, 0.0, 0.0, 0.0], [0.42475441098213196, 0.1372607946395874, 0.12501734495162964, 0.10512828826904297, 0.11353680491447449, 0.09430237114429474, 0.0, 0.0, 0.0], [0.43389081954956055, 0.1015075147151947, 0.1127585917711258, 0.07809566706418991, 0.10153982043266296, 0.07239650189876556, 0.09981117397546768, 0.0, 0.0], [0.3272639513015747, 0.11670466512441635, 0.10152364522218704, 0.09298178553581238, 0.09326539933681488, 0.09584285318851471, 0.0935593992471695, 0.07885824143886566, 0.0], [0.3636876344680786, 0.08691780269145966, 0.09665656834840775, 0.06775829941034317, 0.08763950318098068, 0.06339257955551147, 0.08663001656532288, 0.05982723459601402, 0.08749035000801086]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7837377190589905, 0.2162623405456543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7156338095664978, 0.11566547304391861, 0.16870075464248657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4735740125179291, 0.15636064112186432, 0.1287621110677719, 0.2413032203912735, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4900016784667969, 0.12215019762516022, 0.19101260602474213, 0.06354651600122452, 0.13328899443149567, 0.0, 0.0, 0.0, 0.0], [0.31731516122817993, 0.12876152992248535, 0.12024760991334915, 0.12182576209306717, 0.08787409961223602, 0.22397580742835999, 0.0, 0.0, 0.0], [0.36335623264312744, 0.10380885750055313, 0.17119720578193665, 0.06308066099882126, 0.13297218084335327, 0.05233638361096382, 0.11324834078550339, 0.0, 0.0], [0.23989054560661316, 0.09707875549793243, 0.10179761797189713, 0.10874132066965103, 0.08013171702623367, 0.09284413605928421, 0.07008372247219086, 0.20943213999271393, 0.0], [0.2847200334072113, 0.08473499119281769, 0.14512522518634796, 0.05720434710383415, 0.12208069860935211, 0.051202770322561264, 0.10953899472951889, 0.04504050314426422, 0.1003524586558342]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7410699129104614, 0.25893011689186096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6518270969390869, 0.16361530125141144, 0.18455760180950165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6076868772506714, 0.1466004103422165, 0.14292696118354797, 0.10278575122356415, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5049402117729187, 0.11035196483135223, 0.1374637633562088, 0.09656605869531631, 0.15067802369594574, 0.0, 0.0, 0.0, 0.0], [0.4813138246536255, 0.11987204104661942, 0.1118299588561058, 0.08904819190502167, 0.11725204437971115, 0.08068396151065826, 0.0, 0.0, 0.0], [0.4082798361778259, 0.08629942685365677, 0.10928367078304291, 0.07589387148618698, 0.11802487820386887, 0.07552356272935867, 0.12669478356838226, 0.0, 0.0], [0.41861623525619507, 0.10385257750749588, 0.09041076898574829, 0.07110435515642166, 0.09151764214038849, 0.0608493909239769, 0.09435532987117767, 0.06929376721382141, 0.0], [0.33290547132492065, 0.06996484100818634, 0.09077393263578415, 0.06101135537028313, 0.09639451652765274, 0.06106926128268242, 0.10212302207946777, 0.07797205448150635, 0.10778558254241943]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x19815f8e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = \"1,2,3,4,\"\n",
    "str_tokens = model.to_str_tokens(sequence)\n",
    "\n",
    "logits, cache = model.run_with_cache(sequence, remove_batch_dim=True)\n",
    "attention_patterns = [cache[\"pattern\", layer, \"attn\"] for layer in range(12)]\n",
    "layer = 0\n",
    "attention_pattern = attention_patterns[layer]\n",
    "\n",
    "\n",
    "print(\"Layer 0 Head Attention Patterns:\")\n",
    "cv.attention.attention_patterns(tokens=str_tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence: str) -> List[str]:\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    tokens = encoding.encode(sentence)\n",
    "    try:\n",
    "        tokens_strs = [\n",
    "            encoding.decode_single_token_bytes(token).decode() for token in tokens\n",
    "        ]\n",
    "    except UnicodeDecodeError:\n",
    "        raise Exception(\"Unable to decode tokens from sentence.\")\n",
    "    tokens_strs = [token for token in tokens_strs if token.strip() != \"\"]\n",
    "    # print(tokens_strs)\n",
    "    return tokens_strs\n",
    "\n",
    "def tokenstring_subsequences(sequence: str) -> List[str]: \n",
    "    token_strs = tokenize_sentence(sequence)\n",
    "    subsequences = []\n",
    "    for i in range(len(token_strs)):\n",
    "        subsequences.append(\" \".join(token_strs[:i+1]))\n",
    "    return subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_attention(sequence=\"1,2,3,4,\", model=model):\n",
    "    subsequences = tokenstring_subsequences(sequence)\n",
    "    \n",
    "    best_guesses, confidence_in_top_guesses, topk_predictions = get_all_predictions(sequence, model)\n",
    "\n",
    "    attention = attention_pattern(sequence, model)\n",
    "    print(\"attention: \", attention)\n",
    "    return best_guesses, confidence_in_top_guesses, topk_predictions, attention, subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 50257])\n",
      "torch.Size([9, 5])\n",
      "tensor([[ 198,  464,    1,   32,   40],\n",
      "        [  13,    8, 5985,  198,  362],\n",
      "        [ 830, 4059, 2167,   23,   24],\n",
      "        [  11,   12,   13,    8,  198],\n",
      "        [  18,   19,   20,   17,   16],\n",
      "        [  11,   12,  198,    8,   13],\n",
      "        [  19,   20,   18,   21,   16],\n",
      "        [  11,  198,   12,    8,   13],\n",
      "        [  20,   21,   19,   16,   22]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2240927745.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/2240927745.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1146070459.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_with_attention</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/1146070459.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor'</span> object is not callable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/\u001b[0m\u001b[1;33m2240927745.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/2240927745.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/\u001b[0m\u001b[1;33m1146070459.py\u001b[0m:\u001b[94m6\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpredict_with_attention\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/1146070459.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'Tensor'\u001b[0m object is not callable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_with_attention(\"1,2,3,4,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Get entire attention pattern for each token in the sequence\n",
    "#Then package as API and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 50257])\n",
      "torch.Size([9, 5])\n",
      "tensor([[ 198,  464,    1,   32,   40],\n",
      "        [  13,    8, 5985,  198,  362],\n",
      "        [ 830, 4059, 2167,   23,   24],\n",
      "        [  11,   12,   13,    8,  198],\n",
      "        [  18,   19,   20,   17,   16],\n",
      "        [  11,   12,  198,    8,   13],\n",
      "        [  19,   20,   18,   21,   16],\n",
      "        [  11,  198,   12,    8,   13],\n",
      "        [  20,   21,   19,   16,   22]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2166401044.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/2166401044.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1146070459.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict_with_attention</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/1146070459.py'</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Tensor'</span> object is not callable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/\u001b[0m\u001b[1;33m2166401044.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/2166401044.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/\u001b[0m\u001b[1;33m1146070459.py\u001b[0m:\u001b[94m6\u001b[0m in               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpredict_with_attention\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'/var/folders/tw/f31rms1s2rl85xftp5dz3yp00000gn/T/ipykernel_7044/1146070459.py'\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'Tensor'\u001b[0m object is not callable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(predict_with_attention(\"1,2,3,4,\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2', output_attentions=True)\n",
    "# model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "# outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention = outputs[-1]\n",
    "# type(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs[0].shape\n",
    "# outputs[1][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
